{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GIS 5572 Lab 4\n",
    "\n",
    "Due: 3 weeks from date of assignment\n",
    "\n",
    "Goals\n",
    "\n",
    "1. Build a fully functional real-time data visualization and analysis workflow\n",
    "2. Compare and contrast three types of interpolation: Kriging, IDW, 1 chosen\n",
    "3. Map stations for avg. monthly temp in live map\n",
    "\n",
    "Specifics\n",
    "\n",
    "1. Deliver a notebook/lab writeup that can interpolate last 30 days of NDAWN data live\n",
    "\n",
    "2. Build an ETL to pull the last 30 days of temperature data from the DNAWN site for all of the NDAWN stations. \n",
    "    1. Follow ESRI guide for choosing interpolation methods. Use to justify your methods.\n",
    "\n",
    "3. What does the literature recommend be used for interpolating temperature data? \n",
    "    1. Why? (Find one or two articles to support your claims and reference them in the lab writeup)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stations and Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\ast.py\u001b[0m, in \u001b[0;32mparse\u001b[0m:\nLine \u001b[0;34m35\u001b[0m:    \u001b[34mreturn\u001b[39;49;00m \u001b[36mcompile\u001b[39;49;00m(source, filename, mode, PyCF_ONLY_AST)\n",
      "\u001b[0;31mSyntaxError\u001b[0m: invalid syntax (<string>, line 1)\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "station_set = {'Grafton' : 77'Plaza' : 67,'Jamestown' : 33,'Garrison' : 83,\n",
    "'Bottineau' : 12,'Crary' : 18,'Langdon' : 34,'Baker' : 9,\n",
    "'Bowbells' : 58,'Mott' : 69,'Pillsbury' : 64,'Amidon' : 142,\n",
    "'Denhoff' : 129,'Finley' : 86,'Dickinson' : 20,'Dunn' : 81,\n",
    "'Egeland' : 22,'Mohall' : 41,'Dazey' : 19,'Mayville' : 37,\n",
    "'Karlsruhe' : 59,'Maddock' : 109,'Webster' : 112,'Pekin' : 88,\n",
    "'Alamo' : 98,'Horace' : 32,'Mandan' : 36,'Marion' : 79,\n",
    "'Rolla' : 46,'Cando' : 14,'Epping' : 139,'Harvey' : 27,\n",
    "'Hazen' : 28,'Lisbon' : 76,'Michigan' : 73,'Brampton' : 84,\n",
    "'Croff' : 136,'Tappen' : 68,'Robinson' : 45,'Edmore' : 97,\n",
    "'Hawkeye' : 132,'Genoa' : 107,'Niles' : 113,'Mooreton' : 54,\n",
    "'Cooperstown' : 85,'Inkster' : 80,'Northwood' : 42,'Rugby' : 74,\n",
    "'Towner' : 49,'Ross' : 66,'Carrington' : 15,'Fortuna' : 126,\n",
    "'Ray' : 106,'Walhalla' : 51,'Cavalier' : 16,'Crystal' : 104,\n",
    "'Minot' : 40,'Oakes' : 43,'Galesburg' : 25,'Edgeley' : 21,\n",
    "'Bowman' : 13,'Fingal' : 62,'Liberty' : 135,'Adams' : 111,\n",
    "'Leonard' : 72,'Linton' : 35,'Hope' : 102,'Berthold' : 56,\n",
    "'Charbonneau' : 137,'McLeod' : 39,'Streeter' : 48,\n",
    "'Prosper' : 44,'Steele' : 108,'Williston' : 53,'Courtenay' : 140,\n",
    "'Wishek' : 57,'Wahpeton' : 63,'Werner' : 131,'Bismarck' : 11,\n",
    "'Kempton' : 105,'Zeeland' : 110,'Crosby' : 65,'Sawyer' : 125,\n",
    "'Hillsboro' : 30,'Grenora' : 127,'McHenry' : 38,'Columbus' : 17,\n",
    "'Carson' : 96,'Arnegard' : 138,'Noonan' : 128,'Crane Creek' : 134,\n",
    "'Ekre' : 75,'Forest River' : 24,'Fort Yates' : 89,'Grand Forks' : 26,\n",
    "'Hofflund' : 31,'Little Falls' : 120,'Logan Center' : 141,'Medicine Hole' : 130,\n",
    "'Parkers Prairie' : 116,'Pine Point' : 115,'Rat Lake' : 133,'St. Thomas' : 47,\n",
    "'Turtle Lake' : 50,'Watford City' : 52,\n",
    "#MN\n",
    "'Ada' : 78,'Becker' : 118,'Campbell' : 87,'Clarissa' : 124,\n",
    "'Eldred' : 2,'Fox' : 93,'Greenbush' : 70,'Hubbard' : 119,\n",
    "'Humboldt' : 4,'Kennedy' : 82,'Mavie' : 71,'Ottertail' : 103,\n",
    "'Perham' : 114,'Perley' : 3,'Rice' : 121,'Roseau' : 61,\n",
    "'Sabin' : 60,'Staples' : 122,'Stephen' : 5,'Ulen' : 91,\n",
    "'Wadena' : 117,'Warren' : 6,'Waukon' : 92,'Westport' : 123,\n",
    "'Williams' : 95,\n",
    "#MT\n",
    "'Brorson' : 7,'Dagmar' : 99,'Dooley' : 101,'Froid' : 90,\n",
    "'Redstone' : 100,'Sidney' : 8,\n",
    "#NW\n",
    "'Fargo' : 23,'Hettinger' : 29,\n",
    "#SD\n",
    "'Britton' : 55}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDAWN Request Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import date\n",
    "from io import StringIO\n",
    "\n",
    "class ndawn_request:\n",
    "\n",
    "    def __init__(self, startDate='YYYY-MM-DD', endDate='YYYY-MM-DD', ontology = None, location = None, save = False):\n",
    "\n",
    "        self.start = startDate\n",
    "        self.end = endDate\n",
    "\n",
    "        # List of ontology terms, and their URL codes to build request URL\n",
    "        self.ontology = {\n",
    "            'Air Temperature': ['variable=hdt', 'variable=hdt9'],\n",
    "            'Relative Humidity': ['variable=hdrh', 'variable=hdrh9'],\n",
    "            'Soil Temperature': ['variable=hdbst', 'variable=hdtst'],\n",
    "            'Wind Speed': ['variable=hdws', 'variable=hdmxws', 'variable=hdws10', 'variable=hdmxws10'],\n",
    "            'Wind Direction': ['variable=hdwd', 'variable=hdsdwd', '&variable=hdwd10', 'variable=hdsdwd10'],\n",
    "            'Solar Radiation': ['variable=hdsr'],\n",
    "            'Rainfall': ['variable=hdr'],\n",
    "            'Air Pressure': ['variable=hdbp'],\n",
    "            'Dew Point': ['variable=hddp'],\n",
    "            'Wind Chill': ['variable=hdwc']}\n",
    "        # Concatenate the ontology keys into a list for exception printout later\n",
    "        ontologiesErrorMessage = '\\n'.join(list(self.ontology.keys()))\n",
    "\n",
    "        self.stations = station_set\n",
    "        \n",
    "        # Concatenate station names into a list for exception printout later\n",
    "        stationsErrorMessage = '\\n'.join(list(self.stations.keys()))\n",
    "        self.save = save\n",
    "\n",
    "        # This checks the start and end dates supplied to make sure they are valid\n",
    "        # Start by converting dates into iso format\n",
    "        startDateCheck = date.fromisoformat(startDate)\n",
    "        endDateCheck = date.fromisoformat(endDate)\n",
    "        # If start date is after end date, raise exception\n",
    "        if startDateCheck > endDateCheck:\n",
    "            raise Exception('End date cannot be before start date')\n",
    "        \n",
    "        # Create empty list to hold URL codes for ontology terms\n",
    "        self.activeMeasures = []\n",
    "        # If user supplies ontology terms\n",
    "        if ontology is not None:\n",
    "            for item in ontology:\n",
    "                # If user-supplied term is not in the dictionary, raise exception\n",
    "                if item not in self.ontology.keys():\n",
    "                    raise Exception('Ontology term [' + str(item) + '] not recognized. Available ontology terms include: ' + '\\n' + ontologiesErrorMessage)\n",
    "                # Otherwise, append URL codes for ontology terms into the list of measurements to be requested\n",
    "                else:\n",
    "                    for code in self.ontology[item]:\n",
    "                        self.activeMeasures.append(code)  \n",
    "        # If user does not supply ontology terms, add all URL codes in dictionary to the list of measurements to be requested    \n",
    "        else:\n",
    "            for key in self.ontology:\n",
    "                for code in self.ontology[key]:\n",
    "                    self.activeMeasures.append(code)\n",
    "\n",
    "        # Create empty list to hold URL codes for stations\n",
    "        self.activeStations = []\n",
    "        # If user supplies station names\n",
    "        if location is not None:\n",
    "            for name in location:\n",
    "                # If user-supplied name is not in the dictionary, raise exception\n",
    "                if name not in self.stations.keys():\n",
    "                    raise Exception('Station [' + str(name) + '] not recognized. Available stations include: ' + '\\n' + stationsErrorMessage)\n",
    "                # Otherwise, append URL codes for stations into the list of stations to be requested\n",
    "                else:\n",
    "                    self.activeStations.append('station=' + str(self.stations[name]))\n",
    "        # If user does not supply station names, add all station URL codes in dictionary to the list of stations to be requested\n",
    "        else:    \n",
    "            for key in self.stations:\n",
    "                self.activeStations.append('station=' + str(self.stations[key]))\n",
    "\n",
    "    def get_data(self):\n",
    "        \n",
    "        # Construct API call for the request\n",
    "        baseURL = 'https://ndawn.ndsu.nodak.edu/table.csv?'\n",
    "        stations = '&'.join(self.activeStations)\n",
    "        measurements = '&'.join(self.activeMeasures)\n",
    "        options = '&ttype=hourly&quick_pick=&begin_date=' + self.start + '&end_date=' + self.end\n",
    "        finalURL = str(baseURL + stations + '&' + measurements + options)\n",
    "        \n",
    "        # Request page\n",
    "        page = requests.get(finalURL)\n",
    "        # If status code not 200, raise exception\n",
    "        if page.status_code != 200:\n",
    "            raise Exception('URL request status not 200. Status code = ' + page.status_code)\n",
    "\n",
    "        print('Request successful')\n",
    "\n",
    "        # Convert csv data to string\n",
    "        content = str(page.content)\n",
    "        # Remove large, unnecessary header\n",
    "        trimContent = content[content.find('Station'):len(content)]\n",
    "        # Replace newline/return with string literal newline\n",
    "        formatContent = trimContent.replace('\\\\r\\\\n', '\\n')\n",
    "        # Convert content to file object\n",
    "        contentFile = StringIO(formatContent)\n",
    "\n",
    "        # Read content into pandas dataframe. Second header row contains units\n",
    "        ndawnData = pd.read_csv(contentFile, header = [0, 1])\n",
    "        \n",
    "        # Concatenate headers to include units\n",
    "        # Assign column list to object\n",
    "        columnHeaders = list(ndawnData.columns)\n",
    "        # List of new headers\n",
    "        newHeaderList = []\n",
    "        # Iterate through column names\n",
    "        for number in range(0, len(columnHeaders)):\n",
    "            # If no unit, keep header unchanged, pass into new list\n",
    "            if 'Unnamed' in columnHeaders[number][1]:\n",
    "                newHeaderList.append(columnHeaders[number][0])\n",
    "            # If unit exists, concatenate header and unit, pass into new list\n",
    "            else:\n",
    "                newHeader = columnHeaders[number][0] + ' (' + columnHeaders[number][1] + ') '\n",
    "                newHeaderList.append(newHeader)\n",
    "        # Assign new column names\n",
    "        ndawnData.columns = newHeaderList\n",
    "        # Create single column for datetime\n",
    "        ndawnData['Date'] = pd.to_datetime(ndawnData[['Year', 'Month', 'Day']])\n",
    "        # Save to csv if save option selected\n",
    "        if self.save:\n",
    "            ndawnData.to_csv('ndawnData.csv', index=False)\n",
    "        return ndawnData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2021-04-17\n",
      "30 days ago date: 2021-03-18\n",
      "Request successful\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "import numpy as np\n",
    "\n",
    "# so now we need to loop that function for the last 30 days.\n",
    "#this gets today's date\n",
    "end_day = date.today()\n",
    "start_day = date.today()-timedelta(30)\n",
    "\n",
    "end_day = str(end_day)\n",
    "start_day = str(start_day)\n",
    "\n",
    "print(\"Today's date:\", end_day)\n",
    "print(\"30 days ago date:\", start_day)\n",
    "\n",
    "desired_locations = (list(station_set.keys()))\n",
    "\n",
    "exampleRequest = ndawn_request(startDate=start_day,\n",
    "                               endDate=end_day,\n",
    "                               ontology=['Air Temperature'],\n",
    "                               location=desired_locations,\n",
    "                               save = False)\n",
    "ndawnDF = exampleRequest.get_data()\n",
    "ndawnDF = ndawnDF.filter(['Station Name','Latitude (deg) ','Longitude (deg) ','Avg Air Temp (Degrees F) '], axis=1)\n",
    "grouped = ndawnDF.groupby(\"Station Name\")\n",
    "new_DF = grouped.aggregate(np.mean)\n",
    "new_DF.to_csv(\"GroupedNDAWN.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV to Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Cole\\Documents\\GitHub\\GIS5572\\Lab4\\Lab4\\Default.gdb\\Station_Pts2<h2>Messages</h2>Start Time: Monday, April 19, 2021 2:18:04 PM<br/>WARNING 100160: Some of the features have invalid geometry and have been removed from the result<br/>WARNING 000192: Invalid value for rows: 1<br/>Succeeded at Monday, April 19, 2021 2:18:05 PM (Elapsed Time: 0.80 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Cole\\\\Documents\\\\GitHub\\\\GIS5572\\\\Lab4\\\\Lab4\\\\Default.gdb\\\\Station_Pts2'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy\n",
    "in_table = \"C:\\\\Users\\\\Cole\\\\Documents\\\\GitHub\\\\GIS5572\\\\Lab4\\\\GroupedNDAWN.csv\"\n",
    "arcpy.management.XYTableToPoint(in_table, \"Station_Pts2\",\n",
    "                                \"Longitude (deg)\",\"Latitude (deg)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.workspace = r'C:\\Users\\Cole\\Documents\\GitHub\\GIS5572\\Lab4'\n",
    "\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "\n",
    "inPointFeatures = \"Station_Pts2.shp\"\n",
    "zField = \"Avg Air Temp (Degrees F)\"\n",
    "\n",
    "#ok so 200 is WAY too big\n",
    "cellSize = .01\n",
    "power = 3\n",
    "#searchRadius = RadiusVariable(10, 150)\n",
    "\n",
    "outIDW = arcpy.sa.Idw(inPointFeatures, zField, cellSize, power)\n",
    "outIDW.save(\"IDW_Final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.workspace = r'C:\\Users\\Cole\\Documents\\GitHub\\GIS5572\\Lab4'\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "\n",
    "inFeatures = \"Station_Pts2.shp\"\n",
    "field = \"Avg Air Temp (Degrees F)\"\n",
    "cellSize = .01\n",
    "#outVarRaster = \"C:/sapyexamples/output/outvariance\"\n",
    "lagSize = 2\n",
    "majorRange = 1\n",
    "partialSill = 4\n",
    "nugget = 0\n",
    "\n",
    "kModelOrdinary = KrigingModelOrdinary(\"CIRCULAR\", lagSize, majorRange, partialSill, nugget)\n",
    "kRadius = RadiusFixed(20, 1)\n",
    "outKriging = Kriging(inFeatures, field, kModelOrdinary, cellSize)\n",
    "                    \n",
    "outKriging.save(\"Kriging_final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Cole\\Documents\\GitHub\\GIS5572\\Lab4\\NNbr_final<h2>Messages</h2>Start Time: Monday, April 19, 2021 2:45:02 PM<br/>Succeeded at Monday, April 19, 2021 2:45:03 PM (Elapsed Time: 1.12 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Cole\\\\Documents\\\\GitHub\\\\GIS5572\\\\Lab4\\\\NNbr_final'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.workspace = r'C:\\Users\\Cole\\Documents\\GitHub\\GIS5572\\Lab4'\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "\n",
    "inPntFeat = \"Station_Pts2.shp\"\n",
    "zField = \"Avg Air Temp (Degrees F)\"\n",
    "outRaster = \"NNbr_final\"\n",
    "cellSize = .01\n",
    "\n",
    "# Execute NaturalNeighbor\n",
    "arcpy.NaturalNeighbor_3d(inPntFeat, zField, outRaster, cellSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
